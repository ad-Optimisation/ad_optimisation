{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from os import path\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "import pandas as pd\n",
    "from text_extraction import Text_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extract=Text_extraction()\n",
    "assets = glob.glob('../data/Assets/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDetector():\n",
    "    detector = cv2.ORB_create(nfeatures=2000)\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    detector = createDetector()\n",
    "    kps, descs = detector.detectAndCompute(gray, None)\n",
    "    return kps, descs, img.shape[:2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFeatures(img, train_features):\n",
    "    train_kps, train_descs, shape = train_features\n",
    "    # get features from input image\n",
    "    kps, descs, _ = getFeatures(img)\n",
    "    # check if keypoints are extracted\n",
    "    if not kps:\n",
    "        return None\n",
    "    # now we need to find matching keypoints in two sets of descriptors (from sample image, and from current image)\n",
    "    # knnMatch uses k-nearest neighbors algorithm for that\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.knnMatch(train_descs, descs, k=2)\n",
    "    good = []\n",
    "    # apply ratio test to matches of each keypoint\n",
    "    # idea is if train KP have a matching KP on image, it will be much closer than next closest non-matching KP,\n",
    "    # otherwise, all KPs will be almost equally far\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            good.append([m])\n",
    "    # stop if we didn't find enough matching keypoints\n",
    "    if len(good) < 0.1 * len(train_kps):\n",
    "        return None\n",
    "    # estimate a transformation matrix which maps keypoints from train image coordinates to sample image\n",
    "    src_pts = np.float32([train_kps[m[0].queryIdx].pt for m in good\n",
    "                          ]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kps[m[0].trainIdx].pt for m in good\n",
    "                          ]).reshape(-1, 1, 2)\n",
    "    m, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    if m is not None:\n",
    "        # apply perspective transform to train image corners to get a bounding box coordinates on a sample image\n",
    "        scene_points = cv2.perspectiveTransform(np.float32([(0, 0), (0, shape[0] - 1), (shape[1] - 1, shape[0] - 1), (shape[1] - 1, 0)]).reshape(-1, 1, 2), m)\n",
    "        rect = cv2.minAreaRect(scene_points)\n",
    "        # check resulting rect ratio knowing we have almost square train image\n",
    "        if rect[1][1] > 0 and 0.8 < (rect[1][0] / rect[1][1]) < 1.2:\n",
    "            return rect\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# get train features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m../data/Assets/3bc12d2bdea947d4502e885b6d9aa442/logo.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mgetFeatures(img)\n\u001b[1;32m      4\u001b[0m \u001b[39m# detect features on test image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# get train features\n",
    "img = cv2.imread('../data/Assets/3bc12d2bdea947d4502e885b6d9aa442/logo.png')\n",
    "train_features = features.getFeatures(img)\n",
    "# detect features on test image\n",
    "region = features.detectFeatures(frame, train_features)\n",
    "if region is not None:\n",
    "    # draw rotated bounding box\n",
    "    box = cv2.boxPoints(region)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(img, [box], 0, (0, 255, 0), 2)\n",
    "# display the image\n",
    "cv2.imshow(\"Preview\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m train_img \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder,\u001b[39m'\u001b[39m\u001b[39mlogo.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(query_img) \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(train_img):\n\u001b[0;32m---> 10\u001b[0m     location, bottom_right,top_left, res, img \u001b[39m=\u001b[39m t_matching\u001b[39m.\u001b[39mtemplate_matching_image(train_img, query_img,method\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mTM_CCOEFF_NORMED)\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         logo_feature\u001b[39m.\u001b[39mappend([folder\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],location[\u001b[39m0\u001b[39m],location[\u001b[39m1\u001b[39m],bottom_right[\u001b[39m0\u001b[39m],bottom_right[\u001b[39m1\u001b[39m],top_left[\u001b[39m0\u001b[39m],top_left[\u001b[39m1\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "from logo_extraction import  MatchingDetector\n",
    "t_matching=MatchingDetector('img')\n",
    "folder_list = glob.glob('../data/Assets/*')\n",
    "logo_feature = []\n",
    "for folder in folder_list:\n",
    "    query_img = os.path.join(folder,'_preview.png')\n",
    "    train_img = os.path.join(folder,'logo.png')\n",
    "   \n",
    "    if os.path.exists(query_img) and os.path.exists(train_img):\n",
    "        location, bottom_right,top_left, res, img = t_matching.template_matching_image(train_img, query_img,method=cv2.TM_CCOEFF_NORMED)\n",
    "        if res is not None:\n",
    "            logo_feature.append([folder.split('/')[-1],location[0],location[1],bottom_right[0],bottom_right[1],top_left[0],top_left[1]])\n",
    "        else:\n",
    "            logo_feature.append([folder.split('/')[-1],0,0,0,0,0,0]) \n",
    "    else:\n",
    "        logo_feature.append([folder.split('/')[-1],0,0,0,0,0,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beb26789953ddcd0d4fafde83f340bee23aa0884c59e24dddb82f7574d20d741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
